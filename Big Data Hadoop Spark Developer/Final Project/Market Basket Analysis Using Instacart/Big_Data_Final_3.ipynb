{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81c752c0-175d-4ee4-a57c-dfb3193565ae",
   "metadata": {},
   "source": [
    "# Market Basket Analysis Using Instacart\n",
    "\n",
    "    Dataset description:\n",
    "\n",
    "    Orders CSV: Consists of 3-4 million rows\n",
    "    Products CSV: 50 thousand rows\n",
    "    Aisles CSV: 134 rows\n",
    "    Departments CSV: 21 rows\n",
    "    order_products__SET: 30 million rows where SET is defined as:\n",
    "    order_products _prior csv: 3-2 million previous orders\n",
    "    order_products_train csv: 3-2 million order informationZ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f8a89a-4112-4a84-98b9-357b329821a6",
   "metadata": {},
   "source": [
    "## Objective\n",
    "    Analyze company data in order to assist +business in identifying the day when the most orders were placed in order to provide deals for that day\n",
    "    Determine which department is responsible for the most product launches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee1170e-3d3e-4c6f-ac83-9fedd1df0b9f",
   "metadata": {},
   "source": [
    "### Step 1: Upload file to HDFS\n",
    "    In this case, I am using jupyter notebook on my local docker container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a55e49-5fbe-4f7c-8568-7f9c2f7d06f1",
   "metadata": {},
   "source": [
    "### Step 2: Perform below taks on the dataset with Pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fa39d2-775c-47db-a47f-b45af68a0c00",
   "metadata": {},
   "source": [
    "### Explore the orders CSV file and create a DataFrame and display 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c997738d-375f-4eb3-a3f0-63eb3672cd12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://51e04621b22c:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f7d1a2d2530>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('spark').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5375018-0cf1-4013-8d10-948338815826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+--------+------------+---------+-----------------+----------------------+\n",
      "|order_id|user_id|eval_set|order_number|order_dow|order_hour_of_day|days_since_prior_order|\n",
      "+--------+-------+--------+------------+---------+-----------------+----------------------+\n",
      "| 2539329|      1|   prior|           1|        2|                8|                  null|\n",
      "| 2398795|      1|   prior|           2|        3|                7|                  15.0|\n",
      "|  473747|      1|   prior|           3|        3|               12|                  21.0|\n",
      "| 2254736|      1|   prior|           4|        4|                7|                  29.0|\n",
      "|  431534|      1|   prior|           5|        4|               15|                  28.0|\n",
      "| 3367565|      1|   prior|           6|        2|                7|                  19.0|\n",
      "|  550135|      1|   prior|           7|        1|                9|                  20.0|\n",
      "| 3108588|      1|   prior|           8|        1|               14|                  14.0|\n",
      "| 2295261|      1|   prior|           9|        1|               16|                   0.0|\n",
      "| 2550362|      1|   prior|          10|        4|                8|                  30.0|\n",
      "+--------+-------+--------+------------+---------+-----------------+----------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- eval_set: string (nullable = true)\n",
      " |-- order_number: integer (nullable = true)\n",
      " |-- order_dow: integer (nullable = true)\n",
      " |-- order_hour_of_day: integer (nullable = true)\n",
      " |-- days_since_prior_order: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('instacart/orders.csv',header=True,inferSchema=True)\n",
    "df.show(10)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4188aa0a-ec4e-419a-8890-bd382d8f4f42",
   "metadata": {},
   "source": [
    "### Replace all null values with a dummy '999' value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db84c86b-bff0-42ec-afe4-7fdb89ad7b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3421083"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87e724f4-615d-4a9b-8d58-d19eeaf7ce64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3214874"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.na.drop().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58a4397e-cef8-4f56-b294-a55373854525",
   "metadata": {},
   "outputs": [],
   "source": [
    "treated_df = df.na.fill(999,['days_since_prior_order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8938b68-32b1-4c14-b499-674b92446065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+--------+------------+---------+-----------------+----------------------+\n",
      "|order_id|user_id|eval_set|order_number|order_dow|order_hour_of_day|days_since_prior_order|\n",
      "+--------+-------+--------+------------+---------+-----------------+----------------------+\n",
      "| 2539329|      1|   prior|           1|        2|                8|                 999.0|\n",
      "| 2398795|      1|   prior|           2|        3|                7|                  15.0|\n",
      "|  473747|      1|   prior|           3|        3|               12|                  21.0|\n",
      "| 2254736|      1|   prior|           4|        4|                7|                  29.0|\n",
      "|  431534|      1|   prior|           5|        4|               15|                  28.0|\n",
      "+--------+-------+--------+------------+---------+-----------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "treated_df.createOrReplaceTempView('table')\n",
    "spark.sql('select * from table').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc7d35a-b809-488e-831b-720d96d5a4dc",
   "metadata": {},
   "source": [
    "### Find the busiest day of the week and display it\n",
    "    Examine the orders CSV file and find the busiest day of the week by reading the data as a PySpark DataFrame\n",
    "    Hint:The column “order_dow” represents the day of the week   \n",
    "    Wherein:\n",
    "    Day 0 is Sunday\n",
    "    Day 6 is Saturday, and so on\n",
    "    Display the result that contains the total orders placed on each day of the week (Monday to Sunday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64032c85-c8b6-4a7a-a3dc-4da36563cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('select count(order_id),order_dow\\\n",
    "            from table\\\n",
    "            group by order_dow \\\n",
    "            order by count(order_id) desc').createOrReplaceTempView('busy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0934a96-4a4f-4e82-88dc-0a5539097e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+\n",
      "|count(order_id)|order_dow|\n",
      "+---------------+---------+\n",
      "|         600905|        0|\n",
      "|         587478|        1|\n",
      "|         467260|        2|\n",
      "|         453368|        5|\n",
      "|         448761|        6|\n",
      "|         436972|        3|\n",
      "|         426339|        4|\n",
      "+---------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * from busy').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f616a8a2-3a07-41db-9783-e72d6abb8f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+-----------+\n",
      "|count(order_id)|order_dow|day_of_week|\n",
      "+---------------+---------+-----------+\n",
      "|         600905|        0|     Sunday|\n",
      "|         587478|        1|     Monday|\n",
      "|         467260|        2|    Tuesday|\n",
      "|         453368|        5|     Friday|\n",
      "|         448761|        6|   Saturday|\n",
      "|         436972|        3|  Wednesday|\n",
      "|         426339|        4|   Thursday|\n",
      "+---------------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        select\n",
    "            *,\n",
    "            case order_dow\n",
    "                when 0 then 'Sunday'\n",
    "                when 1 then 'Monday'\n",
    "                when 2 then 'Tuesday'\n",
    "                when 3 then 'Wednesday'\n",
    "                when 4 then 'Thursday'\n",
    "                when 5 then 'Friday'\n",
    "                when 6 then 'Saturday'\n",
    "            end as day_of_week\n",
    "        from \n",
    "            busy\n",
    "        \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935b4c60-80a6-424b-a141-c8d495207cb6",
   "metadata": {},
   "source": [
    "### Give a breakdown of orders by the hour and identify the busiest hour\n",
    "    Select the number of order IDs as “Total_Orders” and the hour at which the order was placed\n",
    "    Display the result that contains total orders and the hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d856b2ad-26df-40c9-8f0d-2bb7a43df4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+\n",
      "|order_hour_of_day|total_orders|\n",
      "+-----------------+------------+\n",
      "|               10|      288418|\n",
      "|               11|      284728|\n",
      "|               15|      283639|\n",
      "|               14|      283042|\n",
      "|               13|      277999|\n",
      "|               12|      272841|\n",
      "|               16|      272553|\n",
      "|                9|      257812|\n",
      "|               17|      228795|\n",
      "|               18|      182912|\n",
      "|                8|      178201|\n",
      "|               19|      140569|\n",
      "|               20|      104292|\n",
      "|                7|       91868|\n",
      "|               21|       78109|\n",
      "|               22|       61468|\n",
      "|               23|       40043|\n",
      "|                6|       30529|\n",
      "|                0|       22758|\n",
      "|                1|       12398|\n",
      "|                5|        9569|\n",
      "|                2|        7539|\n",
      "|                4|        5527|\n",
      "|                3|        5474|\n",
      "+-----------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        select\n",
    "            order_hour_of_day,\n",
    "            count(order_id) as total_orders\n",
    "        from\n",
    "            table\n",
    "        group by\n",
    "            order_hour_of_day\n",
    "        order by\n",
    "            total_orders desc\n",
    "        \"\"\").show(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b8c3c4-b3b9-4585-be14-bf7ec0c5d693",
   "metadata": {},
   "source": [
    "### Identify the most popular item based on the order count by exploring order_products__prior and products datasets\n",
    "    Calculate the top 10 popular items based on the count of orders\n",
    "    Display the result that contains the product name as\n",
    "                    “Popular_product_name” and the count of order id as “Order_Count”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cb8f98-3898-4a44-a88d-72c329b6bb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.read.csv('instacart/order_products__prior.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "edb1c696-c683-4e83-88ac-8ec3fcab0e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.createOrReplaceTempView('order_products_prior')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9abc40a1-1857-425d-a703-9e5a509a6fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------------+---------+\n",
      "|order_id|product_id|add_to_cart_order|reordered|\n",
      "+--------+----------+-----------------+---------+\n",
      "|       2|     33120|                1|        1|\n",
      "|       2|     28985|                2|        1|\n",
      "|       2|      9327|                3|        0|\n",
      "|       2|     45918|                4|        1|\n",
      "|       2|     30035|                5|        0|\n",
      "+--------+----------+-----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * from order_products_prior limit 5').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0c69e8d7-86b9-4c21-938d-b253359cbe0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------+-------------+\n",
      "|product_id|        product_name|aisle_id|department_id|\n",
      "+----------+--------------------+--------+-------------+\n",
      "|         1|Chocolate Sandwic...|      61|           19|\n",
      "|         2|    All-Seasons Salt|     104|           13|\n",
      "|         3|Robust Golden Uns...|      94|            7|\n",
      "|         4|Smart Ones Classi...|      38|            1|\n",
      "|         5|Green Chile Anyti...|       5|           13|\n",
      "+----------+--------------------+--------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = spark.read.csv('instacart/products.csv',header=True,inferSchema=True)\n",
    "df3.createOrReplaceTempView('products')\n",
    "spark.sql('select * from products').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "81814866-7588-408e-a874-435efcdd34cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-----------------+---------+--------------------+--------+-------------+\n",
      "|product_id|order_id|add_to_cart_order|reordered|        product_name|aisle_id|department_id|\n",
      "+----------+--------+-----------------+---------+--------------------+--------+-------------+\n",
      "|     33120|       2|                1|        1|  Organic Egg Whites|      86|           16|\n",
      "|     28985|       2|                2|        1|Michigan Organic ...|      83|            4|\n",
      "|      9327|       2|                3|        0|       Garlic Powder|     104|           13|\n",
      "|     45918|       2|                4|        1|      Coconut Butter|      19|           13|\n",
      "|     30035|       2|                5|        0|   Natural Sweetener|      17|           13|\n",
      "+----------+--------+-----------------+---------+--------------------+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        select\n",
    "            *\n",
    "        from\n",
    "            order_products_prior o\n",
    "        left join\n",
    "            products p using (product_id)\n",
    "        \"\"\").createOrReplaceTempView('joined')\n",
    "spark.sql(\"\"\"\n",
    "    select * from joined limit 5\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c5cbe544-22b9-4fd7-bdee-027d912e3e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-----------+\n",
      "|popular_product_name|product_id|order_count|\n",
      "+--------------------+----------+-----------+\n",
      "|              Banana|     24852|     472565|\n",
      "|Bag of Organic Ba...|     13176|     379450|\n",
      "|Organic Strawberries|     21137|     264683|\n",
      "|Organic Baby Spinach|     21903|     241921|\n",
      "|Organic Hass Avocado|     47209|     213584|\n",
      "|     Organic Avocado|     47766|     176815|\n",
      "|         Large Lemon|     47626|     152657|\n",
      "|        Strawberries|     16797|     142951|\n",
      "|               Limes|     26209|     140627|\n",
      "|  Organic Whole Milk|     27845|     137905|\n",
      "+--------------------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        select\n",
    "            product_name as popular_product_name,\n",
    "            product_id,\n",
    "            count(order_id) as order_count\n",
    "        from\n",
    "            joined\n",
    "        group by\n",
    "            product_name,\n",
    "            product_id\n",
    "        order by\n",
    "            count(order_id) desc\n",
    "        limit\n",
    "            10\n",
    "        \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678a1326-2cd5-48ff-b3a2-504f6cc8c372",
   "metadata": {},
   "source": [
    "### Explore the department dataset and create a DataFrame\n",
    "### Recognize the department which has published the maximum products\n",
    "    Display the department ID that has published the maximum products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "93a93a26-be89-4250-a361-686c437d6edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+\n",
      "|department_id|department|\n",
      "+-------------+----------+\n",
      "|            1|    frozen|\n",
      "|            2|     other|\n",
      "|            3|    bakery|\n",
      "|            4|   produce|\n",
      "|            5|   alcohol|\n",
      "+-------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = spark.read.csv('instacart/departments.csv',header=True,inferSchema=True)\n",
    "df4.createOrReplaceTempView('dept')\n",
    "spark.sql('select * from dept').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2e5a03ce-ecf8-4639-9483-d64dfbc42f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+-----------------+\n",
      "|department_id|   department|count(product_id)|\n",
      "+-------------+-------------+-----------------+\n",
      "|           11|personal care|             6563|\n",
      "|           19|       snacks|             6264|\n",
      "|           13|       pantry|             5371|\n",
      "|            7|    beverages|             4365|\n",
      "|            1|       frozen|             4007|\n",
      "+-------------+-------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "            with tb1 as\n",
    "                (select\n",
    "                    *\n",
    "                from\n",
    "                    products p\n",
    "                join\n",
    "                    dept d using(department_id))\n",
    "            select \n",
    "                department_id,\n",
    "                department,\n",
    "                count(product_id)\n",
    "            from\n",
    "                tb1\n",
    "            group by\n",
    "                department_id, department\n",
    "            order by\n",
    "                count(product_id) desc\n",
    "            limit 5\n",
    "        \"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
