{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0420c1ca-8f1a-4d35-8eff-8a994856479a",
   "metadata": {},
   "source": [
    "# Apache Server Log Analysis\n",
    "\n",
    "## Objective:\n",
    "\n",
    "Perform server log analysis to assist businesses in identifying and analyzing critical business errors, as well as potential customers and their domains\n",
    "\n",
    "Dataset Name: server-access-log.txt (Can be downloaded from the Course Resources tab)\n",
    "\n",
    "Access_log file description:\n",
    "\n",
    "Snippet:\n",
    "\n",
    "10.1.2.3 - rehg [10/Nov/2021:19:22:12 -0000] \"GET /sematext.png HTTP/1.1\" 200 3423\n",
    "\n",
    "The following elements are present in the dataset:\n",
    "\n",
    "%h: Resolved into 10.1.2.3 – the IP address of the remote host that made the request\n",
    "%l: Identd provides the remote log name, with a hyphen, which is a value that can be logged if the information provided by the logging directive cannot be located or accessed\n",
    "%u: Resolved into rehg, the user identifier determined by the HTTP authentication\n",
    "%t: The date and time of the request with the time zone; in the above case it is [10/Nov/2021:19:22:12 -0000]\n",
    "\\”%r\\”: The first line of the request inside double quotes; in the above case it is “GET /sematext.png HTTP/1.1”\n",
    "%>s: The status code reported to the client\n",
    "This information is crucial because it determines whether the request was successful or not.\n",
    "%b: The size of the object sent to the client; in our case, the object was the sematext.png file and its size was 3423 bytes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0566c363-c964-45db-98c4-4d69fc42aaa8",
   "metadata": {},
   "source": [
    "## Status Code Analysis\n",
    "    Read the log file as an RDD in PySpark\n",
    "    Consider the sixth element as it is “request type” and replace   the “single quote\" with blank\n",
    "    Convert each word into a tuple of (word,1)\n",
    "    Apply “reduceByKey“ transformation to count the values\n",
    "    Display the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d50ad741-53cf-4f66-a7fb-563fdb25d409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the log file as an RDD in PySpark via Spark Session and Spark Context\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('spark').getOrCreate()\n",
    "\n",
    "log_rdd = spark.sparkContext.textFile('server-access-log.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e7384bf5-ae4e-4e43-aad9-148159430c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98378"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "527ff2a0-df5a-4728-b495-ece93814fac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('13.66.139.0 - - [19/Dec/2020:13:57:26 +0100] \"GET /index.php?option=com_phocagallery&view=category&id=1:almhuette-raith&Itemid=53 HTTP/1.1\" 200 32653 \"-\" \"Mozilla/5.0 (compatible; bingbot/2.0; +http://www.bing.com/bingbot.htm)\" \"-\"', 0)\n",
      "('157.48.153.185 - - [19/Dec/2020:14:08:06 +0100] \"GET /apache-log/access.log HTTP/1.1\" 200 233 \"-\" \"Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\" \"-\"', 1)\n"
     ]
    }
   ],
   "source": [
    "# Print first few lines to check out the data. collect one line to work with\n",
    "test_line = \"\"\n",
    "for line in zip(log_rdd.collect(),range(2)):\n",
    "    print(line)\n",
    "    test_line = line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3ce7213-db60-4edc-95fb-2dc129843103",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = test_line.split(\" \")[5].replace('\"','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c655d0c0-57ee-470c-bac9-fd926f10d24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = (word,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "881d17c3-3ba9-48fb-9eec-319d280b1b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GET', 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a99b57d3-ec45-4cf0-8afe-75be55998c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_rdd = log_rdd.filter(lambda line : line != \"\")\\\n",
    "        .map(lambda line : (line.split(\" \")[5].replace('\"',''),1))\\\n",
    "        .reduceByKey(lambda a,b:a+b)\n",
    "# .filter for taking out empty lines\n",
    "# .map for doing transformation for each line --> applying function to each line\n",
    "# .reduceByKey is a narrow aggregration function that does local reduce on each\n",
    "# node locally before sending the reduced values to the reduce layer, causing\n",
    "# less network overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b950dbd8-440f-4f0b-855c-fce744bc27a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('GET', 41075)\n",
      "('HEAD', 307)\n",
      "('POST', 56995)\n",
      "('OPTIONS', 1)\n"
     ]
    }
   ],
   "source": [
    "# print result\n",
    "for line in code_rdd.collect():\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d490d5fa-126f-4f7c-9bd1-c005e222d06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('POST', 56995)\n",
      "('GET', 41075)\n",
      "('HEAD', 307)\n",
      "('OPTIONS', 1)\n"
     ]
    }
   ],
   "source": [
    "# sort by descending order\n",
    "ranked_rdd = code_rdd.sortBy(lambda x : x[1],ascending = False)\n",
    "for line in ranked_rdd.collect():\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef17126-96b5-40c2-87f5-63c54bb24600",
   "metadata": {},
   "source": [
    "## Identify the top 10 frequent visitors of the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f867fd10-98d2-4ac3-a107-1d899dceaaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets assume an IP address counts as a visitor\n",
    "visitor_rdd = log_rdd.filter(lambda x : x != \"\")\\\n",
    "                .map(lambda line : (line.split(' ')[0],1))\\\n",
    "                .reduceByKey(lambda a,b : a+b)\\\n",
    "                .sortBy(lambda x : x[1], ascending = False)\n",
    "# filter function eliminates any empty lines\n",
    "# map function transform the row into a tuple (keyIWantToKeep,1) which are later used by\n",
    "# reduceByKey function to count up all instances of the IP address\n",
    "# sortBy is finally used to sort via descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4e47273a-fb01-4058-b89a-536a10527394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('193.106.31.130', 43423), 0)\n",
      "(('173.255.176.5', 5220), 1)\n",
      "(('178.44.47.170', 2824), 2)\n",
      "(('51.210.183.78', 2684), 3)\n",
      "(('45.15.143.155', 1927), 4)\n",
      "(('45.144.0.179', 946), 5)\n",
      "(('176.222.58.254', 934), 6)\n",
      "(('45.132.207.154', 890), 7)\n",
      "(('45.153.227.55', 888), 8)\n",
      "(('45.138.4.22', 880), 9)\n"
     ]
    }
   ],
   "source": [
    "for line in zip(visitor_rdd.collect(),range(10)):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39c73c7-e37c-47d8-abee-ba6dbffd3cf6",
   "metadata": {},
   "source": [
    "## Identify the top 10 missing (does not exist) URLs\n",
    "    Read the log file as an RDD in PySpark\n",
    "    Identify the URLs for which the server is returning the 404-request code and display the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "6d537be3-65c9-48a9-93b8-5854141a6f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    After some data exploratory analysis, I was able to determine that my two needed values are\\nat the 8th and 11th position. Because of this, I used map() to slice the important piece\\n    Then, I use filter to collect entry points with 404 request code\\n    Then, I use map() again to remove extras on the url string\\n    Finally, I used reduceByKey() to count the number of instances of each url, then sort desc\\n'"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_rdd = log_rdd.map(lambda line : line.split(' ')[8:11])\\\n",
    "                    .filter(lambda line : line[0] == '404')\\\n",
    "                    .map(lambda line : (line[2].replace('\"',''),1))\\\n",
    "                    .reduceByKey(lambda a,b : a+b)\\\n",
    "                    .sortBy(lambda line : line[1],ascending=False)\n",
    "\"\"\"\n",
    "    After some data exploratory analysis, I was able to determine that my two needed values are\n",
    "at the 8th and 11th position. Because of this, I used map() to slice the important piece\n",
    "    Then, I use filter to collect entry points with 404 request code\n",
    "    Then, I use map() again to remove extras on the url string\n",
    "    Finally, I used reduceByKey() to count the number of instances of each url, then sort desc\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "c3d39687-2ead-4c7d-adcb-a85700111cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, ('-', 3070))\n",
      "(1, ('http://www.almhuette-raith.at', 609))\n",
      "(2, ('http://www.almhuette-raith.at/', 447))\n",
      "(3, ('http://www.almhuette-raith.at/apache-log/access.log', 398))\n",
      "(4, ('http://www.almhuette-raith.at/apache-log/', 183))\n",
      "(5, ('http://almhuette-raith.at/', 153))\n",
      "(6, ('http://www.almhuette-raith.at/index.php?option=com_phocagallery&view=category&id=1&Itemid=53', 90))\n",
      "(7, ('http://www.almhuette-raith.at/index.php?option=com_content&view=article&id=49&Itemid=55', 68))\n",
      "(8, ('http://www.almhuette-raith.at/index.php?option=com_content&view=article&id=50&Itemid=56', 53))\n",
      "(9, ('http://www.almhuette-raith.at/robots.txt', 51))\n",
      "(10, ('http://www.almhuette-raith.at/index.php?option=com_content&view=article&id=46&Itemid=54', 29))\n"
     ]
    }
   ],
   "source": [
    "# I could've filtered out '-', but I decided to keep it in here because\n",
    "# it reflects the data most accurately ... the most missing url is ... a missing url\n",
    "\n",
    "for line in zip(range(11),missing_rdd.collect()):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bb3853-95ae-4a8c-aab5-232ff7cf7771",
   "metadata": {},
   "source": [
    "## Identify the traffic (total number of HTTP requests received per day)\n",
    "    Read the log file as an RDD in PySpark\n",
    "    Fetch the DateTime string and replace \"[\" with blank\n",
    "    Get the date string from the DateTime\n",
    "    Identify HTTP requests using the map function\n",
    "    Display the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "e361f8b5-b314-4977-8f7a-bd88bb34b0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('28/Dec/2020', 7478),\n",
       " ('25/Dec/2020', 5644),\n",
       " ('18/Jan/2021', 4988),\n",
       " ('11/Jan/2021', 4283),\n",
       " ('08/Jan/2021', 4056),\n",
       " ('21/Dec/2020', 3982),\n",
       " ('23/Dec/2020', 3856),\n",
       " ('20/Dec/2020', 3698),\n",
       " ('22/Dec/2020', 3645),\n",
       " ('24/Dec/2020', 3607),\n",
       " ('07/Jan/2021', 3098),\n",
       " ('29/Dec/2020', 2919),\n",
       " ('09/Jan/2021', 2805),\n",
       " ('04/Jan/2021', 2788),\n",
       " ('17/Jan/2021', 2498),\n",
       " ('13/Jan/2021', 2475),\n",
       " ('30/Dec/2020', 2389),\n",
       " ('06/Jan/2021', 2386),\n",
       " ('03/Jan/2021', 2379),\n",
       " ('16/Jan/2021', 2328),\n",
       " ('10/Jan/2021', 2313),\n",
       " ('19/Jan/2021', 2302),\n",
       " ('12/Jan/2021', 2300),\n",
       " ('26/Dec/2020', 2269),\n",
       " ('15/Jan/2021', 2227),\n",
       " ('20/Jan/2021', 2204),\n",
       " ('27/Dec/2020', 2181),\n",
       " ('01/Jan/2021', 2165),\n",
       " ('31/Dec/2020', 2067),\n",
       " ('05/Jan/2021', 2017),\n",
       " ('14/Jan/2021', 1954),\n",
       " ('02/Jan/2021', 1942),\n",
       " ('19/Dec/2020', 1135)]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_rdd = log_rdd.filter(lambda line : line.split(' ')[7].split(r'/')[0] == 'HTTP')\\\n",
    "                    .map(lambda line : (line.split(' ')[3].replace('[','').split(':')[0],1))\\\n",
    "                    .reduceByKey(lambda a,b:a+b)\\\n",
    "                    .sortBy(lambda line:line[1],ascending=False)\n",
    "\n",
    "traffic_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad76da4-aa23-4e7d-9690-2bcacb58bd7f",
   "metadata": {},
   "source": [
    "## Identify the top 10 endpoints that transfer maximum content in megabytes and display the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "70e10c0d-dec7-47ce-8601-f078a12cab2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('19.734268 Mb', 0)\n",
      "('19.733582 Mb', 1)\n",
      "('19.733209 Mb', 2)\n",
      "('19.732606 Mb', 3)\n",
      "('19.689319 Mb', 4)\n",
      "('19.675282 Mb', 5)\n",
      "('19.674632 Mb', 6)\n",
      "('19.666675 Mb', 7)\n",
      "('19.666118 Mb', 8)\n",
      "('19.655908 Mb', 9)\n"
     ]
    }
   ],
   "source": [
    "max_rdd = log_rdd.filter(lambda line : line.split(' ')[9] != '-')\\\n",
    "                .map(lambda line : int(line.split(' ')[9]))\\\n",
    "                .sortBy(lambda line:line,ascending=False)\n",
    "\n",
    "for line in zip(max_rdd.map(lambda x:str(x/1000000)+\" Mb\").collect(),range(10)):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0087807-d7d8-464f-a802-21ffdead3dff",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "1b2c70a5-d1bc-4117-aae1-974568c8edd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 13.66.139.0\n",
      "1 -\n",
      "2 -\n",
      "3 [19/Dec/2020:13:57:26\n",
      "4 +0100]\n",
      "5 \"GET\n",
      "6 /index.php?option=com_phocagallery&view=category&id=1:almhuette-raith&Itemid=53\n",
      "7 HTTP/1.1\"\n",
      "8 200\n",
      "9 32653\n",
      "10 \"-\"\n",
      "11 \"Mozilla/5.0\n",
      "12 (compatible;\n",
      "13 bingbot/2.0;\n",
      "14 +http://www.bing.com/bingbot.htm)\"\n",
      "15 \"-\"\n"
     ]
    }
   ],
   "source": [
    "for line in zip(log_rdd.map(lambda line : line.split(' ')).collect(),range(1)):\n",
    "    count = 0\n",
    "    for x in line[0]:\n",
    "        print(str(count) + \" \" + x)\n",
    "        count+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
